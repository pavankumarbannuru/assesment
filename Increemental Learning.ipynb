{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69a75e94",
   "metadata": {},
   "source": [
    "https://coderzcolumn.com/tutorials/machine-learning/scikit-learn-incremental-learning-for-large-datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c725a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "1. List of Estimators with \"partial_fit()\" Method \n",
    "Below we have listed estimators which have partial_fit() method available with them.\n",
    "\n",
    "Regression\n",
    "sklearn.linear_model.SGDRegressor\n",
    "sklearn.linear_model.PassiveAggressiveRegressor\n",
    "sklearn.neural_network.MLPRegressor\n",
    "Classification\n",
    "sklearn.naive_bayes.MultinomialNB\n",
    "sklearn.naive_bayes.BernoulliNB\n",
    "sklearn.linear_model.Perceptron\n",
    "sklearn.linear_model.SGDClassifier\n",
    "sklearn.linear_model.PassiveAggressiveClassifier\n",
    "sklearn.neural_network.MLPClassifier\n",
    "Clustering\n",
    "sklearn.cluster.MiniBatchKMeans\n",
    "sklearn.cluster.Birch\n",
    "Preprocessing\n",
    "sklearn.preprocessing.StandardScaler\n",
    "sklearn.preprocessing.MinMaxScaler\n",
    "sklearn.preprocessing.MaxAbsScaler\n",
    "Decomposition / Dimensionality Reduction\n",
    "sklearn.decomposition.MiniBatchDictionaryLearning\n",
    "sklearn.decomposition.IncrementalPCA\n",
    "sklearn.decomposition.LatentDirichletAllocation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05074325",
   "metadata": {},
   "source": [
    "Below is a list of available regression estimators from scikit-learn which supports partial fit on a batch of data for datasets that do not fit into the main memory of the computer.\n",
    "\n",
    "sklearn.linear_model.SGDRegressor\n",
    "sklearn.linear_model.PassiveAggressiveRegressor\n",
    "sklearn.neural_network.MLPRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa97609",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19ed2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, Y = datasets.make_regression(n_samples=240000, random_state=123)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, train_size=0.9, random_state=123)\n",
    "\n",
    "X_train.shape, X_test.shape, Y_train.shape, Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58598160",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = X_train.reshape(-1,24,100), X_test.reshape(-1,24,100)\n",
    "Y_train, Y_test = Y_train.reshape(-1,24), Y_test.reshape(-1,24)\n",
    "\n",
    "X_train.shape, X_test.shape, Y_train.shape, Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004eeba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[0].shape, Y_train[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c0bd6f8",
   "metadata": {},
   "source": [
    "2.2 Create and Train Model\n",
    "In this section, we have created an ML model using SGDRegressor class of scikit-learn. We have then looped through data in batches and trained this estimator by calling partial_fit() method on it for each batch of data. We have also looped through total data 10 times where each time training will be performed in batches.\n",
    "\n",
    "Below we have included a definition of SGDRegressor estimator for explanation purposes.\n",
    "\n",
    "SGDRegressor(loss='squared_error',penalty='l2', alpha=0.0001, l1_ratio=0.15, fit_intercept=True, max_iter=1000, tol=0.001, shuffle=True, verbose=0, epsilon=0.1, random_state=None, learning_rate='invscaling', eta0=0.01, power_t=0.25, early_stopping=False, validation_fraction=0.1,warm_start=False) - This class creates linear model for regression task.\n",
    "The loss parameter accepts one of the below strings specifying loss.\n",
    "'squared_error'\n",
    "'huber'\n",
    "'epsilon_insensitive'\n",
    "'squared_epsilon_insensitive'\n",
    "The penalty parameter accepts string specifying penalty. The possible values of the parameters are 'l2', 'l1' and 'elasticnet'. The default is 'l2'.\n",
    "The l1_ratio parameter accepts float value in the range [0,1] specifying the amount of l1 penalty to use for elasticnet penalty which is a mix of l1 and l2. If a float value of 0 is specified then only l2 penalty is used and a value of 1.0 specifies only the l1 penalty. The value between 0 and 1 specifies the combination of l1 and l2.\n",
    "The fit_intercept parameter accepts boolean values specifying whether to include an intercept in the model or not.\n",
    "The learning_rate parameter accepts one of the below-mentioned strings specifying the learning rate.\n",
    "'constant'\n",
    "'optimal'\n",
    "'invscaling'\n",
    "'adaptive'\n",
    "The validation_fraction parameter accepts float in the range 0-1 specifying how much of training sample should be used for validation. The default is 0.1 which means that 10% of training samples will be used for validation purposes.\n",
    "Below we have created an instance of SGDRegressor with the default parameter. We have then looped through data in batches and called partial_fit() on regressor instance with each batch. We have performed this process for 10 epochs which means we have looped through total training data 10 times in batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e4e771",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDRegressor\n",
    "\n",
    "regressor = SGDRegressor()\n",
    "\n",
    "epochs = 10\n",
    "\n",
    "for k in range(epochs): ## Number of loops through data\n",
    "    for i in range(X_train.shape[0]): ## Looping through batches\n",
    "        X_batch, Y_batch = X_train[i], Y_train[i]\n",
    "        regressor.partial_fit(X_batch, Y_batch) ## Partially fitting data in batches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f0eb7c",
   "metadata": {},
   "source": [
    "2.3 Evaluate Model Performance on Test Data\n",
    "In this section, we have evaluated the performance of our trained model on test data. We have looped through test data in batches and made predictions on them. We have then combined the prediction of each batch.\n",
    "\n",
    "At last, we have calculated MSE and R^2 scores on the test dataset to check the performance of the model.\n",
    "\n",
    "If you are interested in learning about model evaluation metrics using scikit-learn then please feel free to check our tutorial on the same which explains the topic with simple and easy-to-understand examples.\n",
    "\n",
    "Scikit-Learn - Model Evaluation & Scoring Metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6df7750",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "\n",
    "Y_test_preds = []\n",
    "for j in range(X_test.shape[0]): ## Looping through test batches for making predictions\n",
    "    Y_preds = regressor.predict(X_test[j])\n",
    "    Y_test_preds.extend(Y_preds.tolist())\n",
    "\n",
    "print(\"Test MSE      : {}\".format(mean_squared_error(Y_test.reshape(-1), Y_test_preds)))\n",
    "print(\"Test R2 Score : {}\".format(r2_score(Y_test.reshape(-1), Y_test_preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2c674c",
   "metadata": {},
   "outputs": [],
   "source": [
    "2.4 Evaluate Model Performance on Train Data\n",
    "In this section, we have evaluated the performance of our trained model on train data. We have looped through train data in batches and made predictions. We have combined predictions of each batch.\n",
    "\n",
    "At last, we have calculated MSE and R^2 scores on the training dataset to check the performance of the model on train data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc76d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "Y_train_preds = []\n",
    "for j in range(X_train.shape[0]): ## Looping through train batches for making predictions\n",
    "    Y_preds = regressor.predict(X_train[j])\n",
    "    Y_train_preds.extend(Y_preds.tolist())\n",
    "\n",
    "print(\"Train MSE      : {}\".format(mean_squared_error(Y_train.reshape(-1), Y_train_preds)))\n",
    "print(\"Train R2 Score : {}\".format(r2_score(Y_train.reshape(-1), Y_train_preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07f7522",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "### Scaling Data\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "for i in range(X_train.shape[0]):\n",
    "    X_batch, Y_batch = X_train[i], Y_train[i]\n",
    "    scaler.partial_fit(X_batch, Y_batch) ## Partially fitting data in batches\n",
    "\n",
    "\n",
    "### Fitting Data in batches\n",
    "regressor = SGDRegressor()\n",
    "\n",
    "epochs = 10\n",
    "\n",
    "for k in range(epochs):\n",
    "    for i in range(X_train.shape[0]):\n",
    "        X_batch, Y_batch = X_train[i], Y_train[i]\n",
    "        X_batch = scaler.transform(X_batch) ## Preprocessing Single batch of data\n",
    "        regressor.partial_fit(X_batch, Y_batch) ## Partially fitting data in batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca65a8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.decomposition import IncrementalPCA\n",
    "\n",
    "### Scaling Data\n",
    "\n",
    "pca = IncrementalPCA(n_components=20)\n",
    "\n",
    "for i in range(X_train.shape[0]):\n",
    "    X_batch, Y_batch = X_train[i], Y_train[i]\n",
    "    pca.partial_fit(X_batch, Y_batch) ## Partially fitting data in batches\n",
    "\n",
    "\n",
    "### Fitting Data in batches\n",
    "classifier = SGDClassifier()\n",
    "\n",
    "epochs = 20\n",
    "\n",
    "for k in range(epochs):\n",
    "    for i in range(X_train.shape[0]):\n",
    "        X_batch, Y_batch = X_train[i], Y_train[i]\n",
    "        X_batch = pca.transform(X_batch) ## Preprocessing Single batch of data\n",
    "        classifier.partial_fit(X_batch, Y_batch, classes=list(range(2))) ## Partially fitting data in batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ca5f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "Y_test_preds = []\n",
    "for j in range(X_test.shape[0]): ## Looping through test batches for making predictions\n",
    "    X_batch = pca.transform(X_test[j]) ## Preprocessing Single batch of data\n",
    "    Y_preds = classifier.predict(X_batch)\n",
    "    Y_test_preds.extend(Y_preds.tolist())\n",
    "\n",
    "print(\"Test Accuracy      : {}\".format(accuracy_score(Y_test.reshape(-1), Y_test_preds)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e4ea107",
   "metadata": {},
   "source": [
    "Creme, which:\n",
    "\n",
    "Implements a number of popular algorithms for classification, regression, feature selection, and feature preprocessing.\n",
    "Has an API similar to scikit-learn.\n",
    "And makes it super easy to perform online/incremental learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c757a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from creme.linear_model import LogisticRegression\n",
    "from creme.multiclass import OneVsRestClassifier\n",
    "from creme.preprocessing import StandardScaler\n",
    "from creme.compose import Pipeline\n",
    "from creme.metrics import Accuracy\n",
    "from creme import stream\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e26ecc73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eebcf42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3733e399",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
